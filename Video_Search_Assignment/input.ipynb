{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import psycopg2\n",
    "import io\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize  # Corrected import here\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from src.autoencoder import ConvAutoencoder\n",
    "from src.autoencoder import InMemoryCroppedObjectDataset\n",
    "from src.autoencoder import train_autoencoder\n",
    "\n",
    "# Initialization\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "detection_model = fasterrcnn_resnet50_fpn(weight=True).to(device).eval()\n",
    "autoencoder = ConvAutoencoder().to(device).eval()  # Assuming training is done, and we're in inference mode\n",
    "\n",
    "\n",
    "# COCO classes\n",
    "COCO_CLASSES = [\n",
    "    'background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
    "    'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "    'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]  \n",
    "\n",
    "# Transformation for detected objects before passing to the autoencoder\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),  # Match autoencoder input size\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard ImageNet norms\n",
    "])\n",
    "\n",
    "\n",
    "frame_sample_rate = 30  # How often to sample a frame\n",
    "def process_video_and_extract_embeddings(video_path, detection_model, autoencoder, transform, device):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cropped_images =[]\n",
    "    embeddings = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_sample_rate == 0:\n",
    "            # Convert frame to PIL for easier processing and detection\n",
    "            pil_image = Image.fromarray(frame)\n",
    "            img_tensor = T.ToTensor()(pil_image).unsqueeze(0).to(device)\n",
    "\n",
    "            # Object detection\n",
    "            with torch.no_grad():\n",
    "                predictions = detection_model(img_tensor)\n",
    "                \n",
    "            \n",
    "            # Loop through detections\n",
    "            for i, (box, score, label) in enumerate(zip(predictions[0]['boxes'], predictions[0]['scores'], predictions[0]['labels'])):\n",
    "                if score >= 0.5:  # Confidence threshold\n",
    "                    class_name = COCO_CLASSES[label]\n",
    "                    if class_name in COCO_CLASSES:\n",
    "                        # Crop detected object\n",
    "                        box = [round(b.item()) for b in box]\n",
    "                        cropped_obj = pil_image.crop((box[0], box[1], box[2], box[3]))\n",
    "                            \n",
    "                        cropped_images.append(cropped_obj)\n",
    "                        cropped_obj_tensor = transform(cropped_obj).unsqueeze(0).to(device)\n",
    "\n",
    "                        # Pass cropped object through autoencoder to get embedding\n",
    "                        with torch.no_grad():\n",
    "                            _, embedding = autoencoder(cropped_obj_tensor)\n",
    "                            embeddings.append(embedding.squeeze().cpu().numpy())\n",
    "    cap.release()\n",
    "    return embeddings, cropped_images\n",
    "\n",
    "video_path = [\n",
    "    '/Users/sandeebadhikari/Documents/cs370-assignments/Video_Search_Assignment/Downloads/YouTube-Videos/How Green Roofs Can Help Cities  NPR.mp4',\n",
    "    '/Users/sandeebadhikari/Documents/cs370-assignments/Video_Search_Assignment/Downloads/YouTube-Videos/What Does High-Quality Preschool Look Like  NPR Ed.mp4',\n",
    "    '/Users/sandeebadhikari/Documents/cs370-assignments/Video_Search_Assignment/Downloads/YouTube-Videos/Why It’s Usually Hotter In A City  Lets Talk  NPR.mp4'\n",
    "]\n",
    "\n",
    "for path in video_path:\n",
    "    embeddings, cropped_images = process_video_and_extract_embeddings(path, detection_model, autoencoder, transform, device)\n",
    " \n",
    "\n",
    "print(len(cropped_images), len(embeddings))\n",
    "\n",
    "\n",
    "# Now, use all_cropped_images for dataset creation\n",
    "dataset = InMemoryCroppedObjectDataset(cropped_images, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Initialize your autoencoder and device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "autoencoder = ConvAutoencoder().to(device)\n",
    "\n",
    "# Optimizer and loss criterion\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001) \n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Start training\n",
    "train_autoencoder(autoencoder, data_loader, optimizer, criterion, epochs=5, device=device)\n",
    "\n",
    "def image_to_byte_array(image:Image):\n",
    "    imgByteArr = io.BytesIO()\n",
    "    image.save(imgByteArr, format=image.format)\n",
    "    imgByteArr = imgByteArr.getvalue()\n",
    "    return imgByteArr\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=citus user=citus password='Starter$05\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "for cropped_image, embedding in zip(cropped_images, embeddings):\n",
    "    # Convert the PIL Image to bytes\n",
    "    image_data = image_to_byte_array(cropped_image)\n",
    "    # Insert into the database\n",
    "    cur.execute(\"INSERT INTO image_embeddings (image_data, embedding) VALUES (%s, %s)\", (image_data, embedding))\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: /Users/sandeebadhikari/Documents/cs370-assignments/Video_Search_Assignment/YouTube-Videos/How Green Roofs Can Help Cities  NPR.mp4\n",
      "No detections were found.\n",
      "Processing video: /Users/sandeebadhikari/Documents/cs370-assignments/Video_Search_Assignment/YouTube-Videos/What Does High-Quality Preschool Look Like  NPR Ed.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from PIL import Image\n",
    "\n",
    "# Make sure PyTorch is in evaluation mode\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = fasterrcnn_resnet50_fpn(weight=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define the COCO classes\n",
    "COCO_CLASSES = [\n",
    "    'background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
    "    'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "    'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "# List of videos to process\n",
    "video_paths = [\n",
    "    '/Users/sandeebadhikari/Documents/cs370-assignments/Video_Search_Assignment/YouTube-Videos/How Green Roofs Can Help Cities  NPR.mp4',\n",
    "    '/Users/sandeebadhikari/Documents/cs370-assignments/Video_Search_Assignment/YouTube-Videos/What Does High-Quality Preschool Look Like  NPR Ed.mp4',\n",
    "    '/Users/sandeebadhikari/Documents/cs370-assignments/Video_Search_Assignment/YouTube-Videos/Why It’s Usually Hotter In A City  Lets Talk  NPR.mp4'\n",
    "]\n",
    "\n",
    "# Parameters for frame sampling and resizing\n",
    "frame_sample_rate = 30  # How often to sample a frame\n",
    "resize_width = 224\n",
    "resize_height = 224\n",
    "\n",
    "# Directory where you want to save the detection results\n",
    "save_directory = '/Users/sandeebadhikari/Documents/cs370-assignments/Video_Search_Assignment/Detection_Results/'\n",
    "\n",
    "# Ensure the save directory exists, create it if it does not\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "# Function to process a single video and perform object detection\n",
    "def process_and_detect(video_path, frame_sample_rate, resize_dims, model):\n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}.\")\n",
    "        return None\n",
    "\n",
    "    frame_count = 0\n",
    "    detections = []\n",
    "\n",
    "    while True:\n",
    "        # Read frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process frame at specified rate\n",
    "        if frame_count % frame_sample_rate == 0:\n",
    "            # Convert frame to PIL Image and preprocess\n",
    "            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            transform = T.Compose([T.Resize(resize_dims), T.ToTensor()])\n",
    "            transformed_image = transform(pil_image).unsqueeze(0)\n",
    "\n",
    "            # Perform detection\n",
    "            prediction = model(transformed_image)\n",
    "\n",
    "            # Extract detection data\n",
    "            boxes = prediction[0]['boxes']\n",
    "            labels = prediction[0]['labels']\n",
    "            scores = prediction[0]['scores']\n",
    "\n",
    "            for box, label, score in zip(boxes, labels, scores):\n",
    "                if score >= 0.5:\n",
    "                    label_id = int(label.item())\n",
    "                    # Check if the label ID is within the bounds of COCO_CLASSES\n",
    "                    if label_id < len(COCO_CLASSES):\n",
    "                        class_name = COCO_CLASSES[label_id]\n",
    "                    else:\n",
    "                        class_name = 'Unknown'  # Handle out-of-bound label IDs\n",
    "                        \n",
    "                    detections.append([\n",
    "                        os.path.basename(video_path),  # vidId\n",
    "                        frame_count,  # frameNum\n",
    "                        frame_count / cap.get(cv2.CAP_PROP_FPS),  # timestamp (sec)\n",
    "                        label_id,  # detectedObjId\n",
    "                        class_name,  # detectedObjClass\n",
    "                        float(score.item()),  # confidence\n",
    "                        box.tolist()  # bbox info\n",
    "                    ]) \n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return detections\n",
    "\n",
    "# Function to save detections to a CSV file\n",
    "def save_detections(detections, save_path):\n",
    "    with open(save_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['vidId', 'frameNum', 'timestamp', 'detectedObjId', 'detectedObjClass', 'confidence', 'bbox info'])\n",
    "        writer.writerows(detections)\n",
    "        \n",
    "# Process each video and save detection results\n",
    "for video_path in video_paths:\n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    detections = process_and_detect(video_path, frame_sample_rate, (resize_width, resize_height), model)\n",
    "    if detections:\n",
    "        save_path = os.path.join(save_directory, os.path.basename(video_path).replace('.mp4', '_detections.csv'))\n",
    "        save_detections(detections, save_path)\n",
    "        print(f\"Detections saved to {save_path}\")\n",
    "    else:\n",
    "        print(\"No detections were found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
